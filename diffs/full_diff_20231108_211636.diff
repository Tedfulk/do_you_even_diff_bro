from typing import Dict

from py_do_you_even_diff_bro.models import BroMode


SUMMARY_BRO_PROMPT = """Summarize the git dif below in a concise, 1-2 sentence description of the changes made. It will be used as the git commit message. Focus on high-level changes not code level details."""

# CORE_DIFF_SYSTEM_PROMPT = f"""You're diffbro. A programmer's ultimate peer review bro.
# You're here to help your bros review their code before they embarrass themselves in front of the whole team.
# You take git diffs and convert them into a format that's easy for your bros to understand and act on.
# You're a bro, but you're also a brogrammer. You're a diffbrogrammer. You're diffbro.

# Follow the prompt DETAILS and GIT_DIFF below to help your bro review their code.
# """
CORE_DIFF_SYSTEM_PROMPT = """Yo, what's up bro? You're the ultimate code reviewing bro, the diffbro. You got my back when it comes to reviewing my code before you make a fool of yourself in front of the whole team, bro.
You take those gnarly git diffs and transform them into a format that's super easy for me to understand and take action on. You're not just a bro, You're a brogrammer, bro. You're a diffbrogrammer. You're diffy bro, and you're here to help you out.
Dive into the DETAILS and GIT_DIFF I provide, and together, we'll rock this code review like true college coding bros. Let's make some magic happen, bro!
"""

CHILL_BRO_PR_REVIEW_PROMPT = f"""{CORE_DIFF_SYSTEM_PROMPT}

DETAILS:

You're a chill coder BROGRAMMER. Your job is to peer review your bro's code. You look for the big picture stuff and you aren't worried about small details like formatting, naming, pass statements in try blocks, etc. You focus on only code that could lead to critical bugs and nothing else.
You're a chill bro. You're a chill coder bro. You're a chill BROGRAMMER."""

MID_BRO_PR_REVIEW_PROMPT = f"""{CORE_DIFF_SYSTEM_PROMPT}

DETAILS:

You're a mid level coder bro. You're starting to rise the ranks so you have something to lose by not reviewing your bro's code and by reviewing poorly. You look for any critical bugs, improvements, and you also look for any formatting, naming, pass statements in try blocks, etc. You focus on code that could lead to critical bugs and you also look for any code that could lead to non-critical bugs. You're a mid level BROGRAMMER.
"""

CHAD_BRO_PR_REVIEW_PROMPT = """
# Mission
- Outcome or goal: Boost code to legendary status.
- Not procedure: We're here for the gains, not the pain.

# Context
- Background info: It's crunch time, code dojo's open.
- Where in the process are you: Just before we unleash the beast (aka deploy).
- Why does it need to be done: 'Cause no one wants to be the 'It compiled, let's ship it' guy.

# Rules
- Boundaries and constraints: Prioritize bugs by severity like a DJ with tracks.
- Specific subgoals and objectives: Highs then mediums, lows are just the warm-up.

# Instructions
- Do X: Sniff out bugs like a midnight energy drink.
- Do Y: Flex your brain and rate those bugs, bro.
- Do Z: Tidy up that code like it's your dorm room before parents' visit.

# Expected Input
- What to anticipate: A mixed bag of diffs, some clean, some messier than a frat house.
- Variability: From 'just a typo' to 'who wrote this while riding a rollercoaster?'.

# Output Format
- Formatting, type of output, length: Think epic poem but in JSON.
- JSON, XML, lists, etc: JSON, 'cause we're classy.

# Example Output
{
  "summary": "Code review unveiled both champions and challengers in the code.",
  "severities": {
    "high": [
      {
        "bug_id": "B9001",
        "description": "Memory leak in the arena's foundation (data processing module)."
      }
    ],
    "medium": [
      {
        "bug_id": "B9002",
        "description": "Slow chariot race (inefficient database query)."
      }
    ],
    "low": [
      {
        "bug_id": "B9003",
        "description": "Crooked helmet crest (misaligned comment formatting)."
      }
    ]
  },
  "suggestions": {
    "high": [
      {
        "bug_id": "B9001",
        "improvements": "Strengthen the arena's foundation by plugging the memory leak. Consider using smart pointers for automatic resource management.",
        "code": "def process_data(data: List[str]) -> None: # FIXME: Potential memory leak here"
      }
    ],
    "medium": [
      {
        "bug_id": "B9002",
        "improvements": "Speed up the chariot by optimizing the database query. Add indexes or restructure the query for better performance.",
        "code": "SELECT * FROM chariots WHERE speed < 5 # FIXME: Inefficient query, consider indexing"
      }
    ]
  }
}
"""
# CHAD_BRO_PR_REVIEW_PROMPT = f"""{CORE_DIFF_SYSTEM_PROMPT}

# DETAILS:

# Yo, CodeMaster Chad here! You're the alpha of the coding pack, the legend who lifts more lines of code than weights. Your job? Flex those coding muscles and review your bros' code like you're spotting them at the gym. 
# Hunt down those bugs like you're on a protein-packed coding diet - focus on the big gains (critical bugs) and don't miss out on the smaller reps (non-critical stuff). Your code should be as clean and ripped as your post-workout selfie.
# Rate those bugs like you're judging a beach body contest: high, medium, low. Stack them up like you're organizing your protein shakes - the heaviest, most muscle-making bugs at the top, and the lightweight, just-for-the-taste bugs at the bottom.
# Remember, you're the Chad of the Code. Double-check everything like you check yourself out in the mirror. Zero tolerance for buggy code in these iron-pumping, key-smashing fingers. Let's make this code as buff as our biceps, bro!
"""
# CHAD_BRO_PR_REVIEW_PROMPT = f"""{CORE_DIFF_SYSTEM_PROMPT}

# DETAILS:

# You're a chad coder bro. You're at the top of the ranks so you have a lot to lose by not reviewing your bro's code and by reviewing poorly.
# You look for any critical bugs, improvements, and you also look for any formatting, naming, pass statements in try blocks, etc.
# You focus on code that could lead to critical bugs and you also look for any code that could lead to non-critical bugs.
# You also look for any code that could lead to non-critical bugs.

# You diligently report each bug or issue on a low, medium, high scale. You organize them so that the most critical bugs are at the top of the list and the least critical bugs are at the bottom of the list.
# Nothing gets past you, you triple check everything. You're a chad coder BROGRAMMER.
# """

MAP_BRO_MODE_TO_PROMPT: Dict[BroMode, str] = {
    BroMode.CHILL: CHILL_BRO_PR_REVIEW_PROMPT,
    BroMode.MID: MID_BRO_PR_REVIEW_PROMPT,
    BroMode.CHAD: CHAD_BRO_PR_REVIEW_PROMPT,
}


def get_diff_prompt(bro_mode: BroMode, git_diff: str) -> str:
    """
    Returns the prompt for the given bro mode and git diff
    """
    # print(MAP_BRO_MODE_TO_PROMPT[bro_mode])
    return f"""{MAP_BRO_MODE_TO_PROMPT[bro_mode]}

GIT_DIFF:

{git_diff}

"""
import typer
from typer import Option, Argument, prompt, confirm
from typing import List
from rich.console import Console
from rich.table import Table
from py_do_you_even_diff_bro.commandments import SUMMARY_BRO_PROMPT, get_diff_prompt
from py_do_you_even_diff_bro.constants import (
    DETAILED_BROGRAMMER_DESCRIPTION,
    PROGRAMMING_FILE_EXTENSIONS,
)
from py_do_you_even_diff_bro.git import get_git_diff
from py_do_you_even_diff_bro.models import BroMode
from py_do_you_even_diff_bro.llm import gpt_prompt


app = typer.Typer(
    name="BROGRAMMER",
    help="BROGRAMMER: Your AI Peer Review Bro",
    epilog=DETAILED_BROGRAMMER_DESCRIPTION,
)
console = Console()


def get_bro_mode(chill: bool, mid: bool, chad: bool) -> BroMode:
    mode_map = {chill: BroMode.CHILL, mid: BroMode.MID, chad: BroMode.CHAD}
    return next((mode for cond, mode in mode_map.items() if cond), BroMode.CHILL)


def display_diff_summary(summary_diff_response: str):
    table = Table(show_header=True, header_style="bold magenta")
    table.add_column("Summary", justify="left")
    table.add_row(summary_diff_response)
    console.print(table)


def validate_extensions(
    ctx: typer.Context, param: typer.CallbackParam, value: List[str]
) -> List[str]:
    invalid_exts = [ext for ext in value if ext not in PROGRAMMING_FILE_EXTENSIONS]
    if invalid_exts:
        for ext in invalid_exts:
            console.log(f"Invalid file extension: {ext}", style="bold red")
        raise typer.BadParameter(f"Invalid extensions: {', '.join(invalid_exts)}")
    return value


@app.command()
def main(
    chill: bool = typer.Option(
        False,
        "--chill",
        "-c",
        help="Get a chill, jr-level engineer, relaxed BROGRAMMER PR review",
    ),
    mid: bool = typer.Option(
        False, "--mid", "-m", help="Get a mid-level engineer, BROGRAMMER PR review"
    ),
    chad: bool = typer.Option(
        False,
        "--chad",
        "-d",
        help="Get a chad, sr-level engineer, intense BROGRAMMER PR review",
    ),
    model: str = typer.Option(
        "gpt-4", "--model", "-o", help="GPT model use 'gpt-3.5-turbo' or 'gpt-4'"
    ),
    only: list[str] = typer.Option(
        PROGRAMMING_FILE_EXTENSIONS,
        "--only",
        callback=validate_extensions,
        help="Only include files with these extensions",
    ),
    ignore: list[str] = typer.Option(
        [],
        "--ignore",
        callback=validate_extensions,
        help="Ignore files with these extensions",
    ),
    prompt: str = typer.Option("", "--prompt", "-p", help="Specify a custom prompt"),
    summarize: bool = typer.Option(
        False, "--summarize", "-s", help="Summarize the git diff"
    ),
    peer_review: str = typer.Option(
        "",
        "--peer-review",
        "-r",
        help="Specify the branch to compare the git diff against",
    ),
):
    try:
        valid_models = ["gpt-3.5-turbo", "gpt-4"]
        if model not in valid_models:
            console.log(
                "Invalid model. Choose from 'gpt-3.5-turbo' or 'gpt-4'",
                style="bold red",
            )
            return

        invalid_only_exts = [
            ext for ext in only if ext not in PROGRAMMING_FILE_EXTENSIONS
        ]
        invalid_ignore_exts = [
            ext for ext in ignore if ext not in PROGRAMMING_FILE_EXTENSIONS
        ]

        if invalid_only_exts or invalid_ignore_exts:
            if invalid_only_exts:
                console.log(
                    f"Invalid file extensions in --only: {', '.join(invalid_only_exts)}",
                    style="bold red",
                )
            if invalid_ignore_exts:
                console.log(
                    f"Invalid file extensions in --ignore: {', '.join(invalid_ignore_exts)}",
                    style="bold red",
                )
            return

        if sum([chill, mid, chad]) > 1:
            console.log(
                "Only one of --chill, --mid, or --chad can be True.", style="bold red"
            )
            return

        bro_mode = get_bro_mode(chill, mid, chad)

        git_diff = get_git_diff(only, ignore, peer_review)

        if not git_diff:
            print(f"No git diff for BROGRAMMER")
            return

        print(
            f"Building prompt for BROGRAMMER in bromode: '{str(bro_mode)}' mode on GPT model '{model}'"
            f"{f' with custom prompt: {prompt}' if prompt else ''}"
            f"{f' Will generate diff summary.' if summarize else ''}"
        )

        if summarize:
            print(f"\n\nSummarizing git diff for BROGRAMMER on GPT model '{model}'")

            summary_prompt_text = f"{SUMMARY_BRO_PROMPT}\n\n{git_diff}"

            summary_diff_response = gpt_prompt(summary_prompt_text, model)
            display_diff_summary(summary_diff_response)
        else:
            if not prompt:
                prompt_text = get_diff_prompt(bro_mode, git_diff)
            else:
                prompt_text = f"{prompt}\n\n{git_diff}"

            print(f"Running BROGRAMMER")

            diff_response = gpt_prompt(prompt_text, model)

            print("\nBROGRAMMER\n\n", diff_response)
    except Exception as e:
        console.log(f"An error occurred: {e}", style="bold red")


if __name__ == "__main__":
    app()
from py_do_you_even_diff_bro.utils import StrEnum
from pydantic import BaseModel, Field, validator
from typing import List, Optional
from datetime import datetime


class BroMode(StrEnum):
    CHILL = "chill"
    MID = "mid"
    CHAD = "chad"


class BugBase(BaseModel):
    bug_id: str
    description: str

    @validator("bug_id")
    def validate_bug_id(cls, v):
        if not v.startswith("B") or not v[1:].isdigit():
            raise ValueError("bug_id must start with B followed by numbers")
        return v


class BugReport(BugBase):
    pass


class BugImprovement(BugBase):
    improvements: str
    code: str


class SeverityReports(BaseModel):
    high: Optional[List[BugReport]] = []
    medium: Optional[List[BugReport]] = []
    low: Optional[List[BugReport]] = []


class SeverityImprovements(BaseModel):
    high: Optional[List[BugImprovement]] = []
    medium: Optional[List[BugImprovement]] = []


class MetaData(BaseModel):
    timestamp: Optional[datetime] = Field(default_factory=datetime.utcnow)
    session_id: Optional[str]
    user_info: Optional[dict]


class ErrorModel(BaseModel):
    error_message: Optional[str]
    error_code: Optional[int]


class CodeReview(BaseModel):
    summary: str
    severities: SeverityReports
    suggestions: SeverityImprovements
    metadata: Optional[MetaData] = Field(default_factory=MetaData)
    error: Optional[ErrorModel]
import subprocess
from enum import Enum
from typing import Type
from datetime import datetime
import os


class StrEnum(str, Enum):
    """Enum with string values."""

    def __str__(self) -> str:
        """Return the value of the enum as a string.
        Example:
            >>> class MyEnum(StrEnum):
            ...     one = "one string"
            ...     two = "two string"
            >>> str(MyEnum.one) === "one string"
        """
        return self.value

    @staticmethod
    def get_enum_by_values(instance: Type["StrEnum"]) -> list[str]:
        """Get enum by value.
        Example:
            >>> class MyEnum(StrEnum):
            ...     one = "one string"
            ...     two = "two string"
            >>> StrEnum.get_enum_by_values(MyEnum) === ["one string", "two string"]
        """
        return [member.value for member in instance]

    @staticmethod
    def get_enum_by_names(instance: Type["StrEnum"]) -> list[str]:
        """Get enum by name.
        Example:
            >>> class MyEnum(StrEnum):
            ...     one = "one string"
            ...     two = "two string"
            >>> StrEnum.get_enum_by_names(MyEnum) === ["one", "two"]
        """
        return [member.name for member in instance]


def run_shell_command(command: str) -> str:
    process = subprocess.Popen(command, stdout=subprocess.PIPE, shell=True)
    output, error = process.communicate()

    if error:
        print(f"Error: {error}")
        return None
    else:
        return output.decode("utf-8")
[tool.poetry]
name = "do-you-even-diff-bro"
version = "0.1.0"
description = "An AI code bro to review your diff locally."
authors = ["Ted Fulk <tfulk@getspiffy.com>"]
readme = "README.md"

[tool.poetry.dependencies]
python = "3.11.3"
openai = "^0.28.1"
pre-commit = "^3.5.0"
pytest = "^7.4.3"
pydantic = "^2.4.2"
typer = {extras = ["all"], version = "^0.9.0"}
pytest-mock = "^3.12.0"
unidiff = "^0.7.5"


[tool.poetry.group.dev.dependencies]
ipython = "^8.17.1"
isort = "^5.12.0"
black = "^23.10.1"

[build-system]
requires = ["poetry-core"]
build-backend = "poetry.core.masonry.api"
import pytest

import py_do_you_even_diff_bro.main
from py_do_you_even_diff_bro.main import (
    display_diff_summary,
    get_bro_mode,
    get_git_diff,
    main,
)
from py_do_you_even_diff_bro.models import BroMode


def test_get_bro_mode():
    assert get_bro_mode(True, False, False) == BroMode.CHILL
    assert get_bro_mode(False, True, False) == BroMode.MID
    assert get_bro_mode(False, False, True) == BroMode.CHAD
    assert get_bro_mode(False, False, False) == BroMode.CHILL


def test_display_diff_summary(mocker):
    mocker.patch("py_do_you_even_diff_bro.main.console")
    display_diff_summary("Test summary")
    py_do_you_even_diff_bro.main.console.print.assert_called_once()


@pytest.mark.parametrize(
    "chill, mid, chad, model, only, ignore, prompt, summarize, peer_review",
    [
        (True, False, False, "gpt-4", [".py"], [], "", False, ""),
        (
            False,
            True,
            False,
            "gpt-3.5-turbo",
            [".py"],
            [".ts"],
            "Test prompt",
            True,
            "main",
        ),
    ],
)
def test_main(
    chill, mid, chad, model, only, ignore, prompt, summarize, peer_review, mocker
):
    mocker.patch("py_do_you_even_diff_bro.main.get_git_diff", return_value="Test diff")
    mocker.patch(
        "py_do_you_even_diff_bro.main.gpt_prompt", return_value="Test response"
    )
    main(chill, mid, chad, model, only, ignore, prompt, summarize, peer_review)
    if get_git_diff:
        py_do_you_even_diff_bro.main.get_git_diff.assert_called_once_with(
            only, ignore, peer_review
        )
    else:
        py_do_you_even_diff_bro.main.get_git_diff.assert_not_called()
    py_do_you_even_diff_bro.main.gpt_prompt.assert_called()


# Test with a different model
def test_main_with_different_model(mocker):
    mocker.patch("py_do_you_even_diff_bro.main.get_git_diff", return_value="Test diff")
    mocker.patch(
        "py_do_you_even_diff_bro.main.gpt_prompt", return_value="Test response"
    )
    main(
        False,
        True,
        False,
        "gpt-3.5-turbo",
        [".py"],
        [".ts"],
        "Test prompt",
        True,
        "main",
    )
    py_do_you_even_diff_bro.main.get_git_diff.assert_called_once_with(
        [".py"], [".ts"], "main"
    )
    py_do_you_even_diff_bro.main.gpt_prompt.assert_called()


# Test with a different file type
def test_main_with_different_file_type(mocker):
    mocker.patch("py_do_you_even_diff_bro.main.get_git_diff", return_value="Test diff")
    mocker.patch(
        "py_do_you_even_diff_bro.main.gpt_prompt", return_value="Test response"
    )
    main(
        False,
        True,
        False,
        "gpt-3.5-turbo",
        [".java"],
        [".ts"],
        "Test prompt",
        True,
        "main",
    )
    py_do_you_even_diff_bro.main.get_git_diff.assert_called_once_with(
        [".java"], [".ts"], "main"
    )
    py_do_you_even_diff_bro.main.gpt_prompt.assert_called()


# Test with a different prompt value
def test_main_with_different_prompt(mocker):
    mocker.patch("py_do_you_even_diff_bro.main.get_git_diff", return_value="Test diff")
    mocker.patch(
        "py_do_you_even_diff_bro.main.gpt_prompt", return_value="Test response"
    )
    main(
        False,
        True,
        False,
        "gpt-3.5-turbo",
        [".py"],
        [".ts"],
        "Different prompt",
        True,
        "main",
    )
    py_do_you_even_diff_bro.main.get_git_diff.assert_called_once_with(
        [".py"], [".ts"], "main"
    )
    py_do_you_even_diff_bro.main.gpt_prompt.assert_called()


# Test with a different peer_review value
def test_main_with_different_peer_review(mocker):
    mocker.patch("py_do_you_even_diff_bro.main.get_git_diff", return_value="Test diff")
    mocker.patch(
        "py_do_you_even_diff_bro.main.gpt_prompt", return_value="Test response"
    )
    main(
        False,
        True,
        False,
        "gpt-3.5-turbo",
        [".py"],
        [".ts"],
        "Test prompt",
        True,
        False,
    )
    py_do_you_even_diff_bro.main.get_git_diff.assert_called_once_with(
        [".py"], [".ts"], False
    )
    py_do_you_even_diff_bro.main.gpt_prompt.assert_called()


# Test with a different summarize value
def test_main_with_different_summarize(mocker):
    mocker.patch("py_do_you_even_diff_bro.main.get_git_diff", return_value="Test diff")
    mocker.patch(
        "py_do_you_even_diff_bro.main.gpt_prompt", return_value="Test response"
    )
    main(
        False,
        True,
        False,
        "gpt-3.5-turbo",
        [".py"],
        [".ts"],
        "Test prompt",
        False,
        "main",
    )
    py_do_you_even_diff_bro.main.get_git_diff.assert_called_once_with(
        [".py"], [".ts"], "main"
    )
    py_do_you_even_diff_bro.main.gpt_prompt.assert_called()


# Test error scenario
def test_main_with_error(mocker):
    mocker.patch(
        "py_do_you_even_diff_bro.main.get_git_diff", side_effect=Exception("Test error")
    )
    if not get_git_diff:
        with pytest.raises(Exception, match="Test error"):
            main(
                False,
                True,
                False,
                "gpt-3.5-turbo",
                [".py"],
                [".ts"],
                "Test prompt",
                True,
                "main",
            )
